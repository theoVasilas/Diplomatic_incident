{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('/home/theo_ubuntu/Diplomatic_incident/HE/TenSEAL/My_HE_FHE/'))\n",
    "\n",
    "from HE_functions import Ckks_init, Encrypt_model, Dencrypt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 2048, 'coeff': '[20, 20, 14]'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_csv_as_dicts(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries where keys are column names \n",
    "              and values are parsed based on the content.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            parsed_row = {}\n",
    "            for key, value in row.items():\n",
    "                # Attempt to parse each value into int, float, or leave as string\n",
    "                try:\n",
    "                    parsed_row[key] = int(value)\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        parsed_row[key] = float(value)\n",
    "                    except ValueError:\n",
    "                        parsed_row[key] = value\n",
    "            data.append(parsed_row)\n",
    "            \n",
    "    return data\n",
    "\n",
    "valid_config = load_csv_as_dicts(\"valid_config_2.csv\")\n",
    "valid_config[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def batch_parameters(params: List[np.ndarray], slot_count: int) -> List[List[np.ndarray]]:\n",
    "    batched = [params[i:i + slot_count] for i in range(0, len(params), slot_count)]\n",
    "    # print(f\"Number of parts: {len(batched)}\")\n",
    "    return batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts\n",
    "import math\n",
    "from models import Net_Mnist, Net_Cifar\n",
    "from model_utils import get_parameters, flatten_params, reshape_params\n",
    "from model_utils import set_parameters, test_flatten_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baching_HE(num_clients, global_model):\n",
    "    statistics = []\n",
    "\n",
    "    for Selected_key in range(len(valid_config)):\n",
    "\n",
    "        degree = valid_config[Selected_key]['degree']\n",
    "        slot_count = degree // 2\n",
    "        coeff_modulus = list(map(int, valid_config[Selected_key]['coeff'].strip(\"[]\").split(\",\")))\n",
    "        print(f\"degree: {degree}, slot_count: {slot_count}, coeff_modulus: {coeff_modulus}\")\n",
    "\n",
    "        context = Ckks_init(degree,coeff_modulus)\n",
    "\n",
    "        original_params = get_parameters(global_model)\n",
    "        Global_shapes = flatten_params(original_params)[1]\n",
    "        flat_params = flatten_params(original_params)[0]\n",
    "        print(len(flat_params))\n",
    "\n",
    "        ## =========== CLIENTS ==================== ##\n",
    "        local_models = [None] * num_clients\n",
    "\n",
    "        for client_id in range(num_clients):\n",
    "            params = get_parameters(global_model)\n",
    "            flat_params = flatten_params(params)[0]\n",
    "            batched = batch_parameters(flat_params, slot_count)\n",
    "            local_models[client_id] = batched\n",
    "        \n",
    "        ## =========== CLIENTS ==================== ##\n",
    "\n",
    "        clients_encrypted_batches = []\n",
    "        sum_ciphertext_size = 0\n",
    "        for client_id in range(num_clients):\n",
    "            encrypted_batches = []\n",
    "            for batch in batched:\n",
    "                encrypted_batch = ts.ckks_vector(context, batch)\n",
    "                #encrypted_batch = np.array(batch)\n",
    "                encrypted_batches.append(encrypted_batch)\n",
    "                sum_ciphertext_size += len(encrypted_batch.serialize())\n",
    "\n",
    "            clients_encrypted_batches.append(encrypted_batches)\n",
    "        print(len(clients_encrypted_batches))\n",
    "\n",
    "        diff_encrypted_batches = [\n",
    "            batch[0] - batch[1] for batch in zip(*clients_encrypted_batches)\n",
    "        ]\n",
    "\n",
    "        decrypted_params = []\n",
    "        for batch in diff_encrypted_batches:  \n",
    "            decrypted_batch = np.array(batch.decrypt())\n",
    "            #decrypted_batch = np.array(batch)\n",
    "            decrypted_params.append(decrypted_batch)\n",
    "        print(len(decrypted_params))\n",
    "        decrypted_params = np.concatenate(decrypted_params, axis=0)\n",
    "        print(len(decrypted_params))\n",
    "\n",
    "\n",
    "        reshaped_batch = reshape_params(decrypted_params, Global_shapes)\n",
    "        set_parameters(global_model, reshaped_batch)\n",
    "        test_flatten_reshape(original_params, reshaped_batch)\n",
    "\n",
    "        print(f\"Sum ciphertext size: {convert_size(sum_ciphertext_size)} \")\n",
    "\n",
    "        statistics.append([degree, slot_count, coeff_modulus, sum_ciphertext_size])\n",
    "    \n",
    "    return statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "global_model = Net_Cifar()\n",
    "\n",
    "# statistics = test_baching_HE(num_clients, global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree: 2048, slot_count: 1024, coeff_modulus: [20, 20, 14]\n",
      "reshaped_batch [(6, 3, 5, 5), (6,), (16, 6, 5, 5), (16,), (120, 400), (120,), (84, 120), (84,), (10, 84), (10,)]\n",
      "num of clients encrypted_batches  10\n",
      "num of batches for a client 61\n",
      "batches after sum 61\n",
      "decrypted_batches 62006\n",
      "reshaped_batch [(6, 3, 5, 5), (6,), (16, 6, 5, 5), (16,), (120, 400), (120,), (84, 120), (84,), (10, 84), (10,)]\n"
     ]
    }
   ],
   "source": [
    "Selected_key = -1\n",
    "\n",
    "degree = valid_config[Selected_key]['degree']\n",
    "slot_count = degree // 2\n",
    "coeff_modulus = list(map(int, valid_config[Selected_key]['coeff'].strip(\"[]\").split(\",\")))\n",
    "print(f\"degree: {degree}, slot_count: {slot_count}, coeff_modulus: {coeff_modulus}\")\n",
    "\n",
    "context = Ckks_init(degree,coeff_modulus)\n",
    "\n",
    "original_params = get_parameters(global_model)\n",
    "Global_shapes = flatten_params(original_params)[1]\n",
    "print(\"reshaped_batch\",Global_shapes)\n",
    "\n",
    "# flat_params = flatten_params(original_params)[0]\n",
    "# batched = batch_parameters(flat_params, slot_count)\n",
    "# print(len(batched))\n",
    "# print(len(flat_params))\n",
    "\n",
    "## ============================== CLIENTS ================================== ##\n",
    "clients_encrypted_batches = []\n",
    "for client_id in range(num_clients):\n",
    "    params = get_parameters(global_model)\n",
    "    \n",
    "    ## training \n",
    "\n",
    "    flat_params = flatten_params(params)[0]\n",
    "    batched = batch_parameters(flat_params, slot_count)\n",
    "    encrypted_batches = []\n",
    "    for batch in batched:\n",
    "        encrypted_batch = ts.ckks_vector(context, batch)\n",
    "        encrypted_batches.append(encrypted_batch)\n",
    "\n",
    "    clients_encrypted_batches.append(encrypted_batches)\n",
    "\n",
    "print(\"num of clients encrypted_batches \",len(clients_encrypted_batches))\n",
    "print(\"num of batches for a client\",len(clients_encrypted_batches[0]))\n",
    "\n",
    "# =============================== SERVER ======================================= #\n",
    "\n",
    "sumed_encrypted_batches = [\n",
    "    sum(batch) for batch in zip(*clients_encrypted_batches)\n",
    "]\n",
    "print(\"batches after sum\",len(sumed_encrypted_batches))\n",
    "\n",
    "\n",
    "decrypted_params = np.concatenate([batch.decrypt() for batch in sumed_encrypted_batches]) / num_clients\n",
    "print(\"decrypted_batches\",len(decrypted_params))\n",
    "\n",
    "reshaped_batch = reshape_params(decrypted_params, Global_shapes)\n",
    "print(\"reshaped_batch\",flatten_params(reshaped_batch)[1])\n",
    "set_parameters(global_model, reshaped_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrypted_batches 62006\n"
     ]
    }
   ],
   "source": [
    "decrypted_batches = np.concatenate([batch.decrypt() for batch in sumed_encrypted_batches])\n",
    "print(\"decrypted_batches\",len(decrypted_batches))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

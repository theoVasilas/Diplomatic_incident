{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObqJNL4PUpqCHrijVf4G5j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theoVasilas/Diplomatic_incident/blob/simulation/Fed_2_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "nm_KsFraeQNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbXGZcJBcrVT"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedAdagrad\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81QRVoGVe1iY",
        "outputId": "295b9eee-8d55-4178-bf81-2592328e0552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.12.0 / PyTorch 2.5.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "G90OvWHyipUa",
        "outputId": "837df8e3-c726-4ca6-99d1-9aa141ce62a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader\n"
      ],
      "metadata": {
        "id": "C8jpPOMUeesL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import IidPartitioner\n",
        "\n",
        "NUM_PARTITIONS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "    # Initialize the FederatedDataset with partitioning scheme\n",
        "    fds = FederatedDataset(\n",
        "        dataset=\"mnist\",\n",
        "        partitioners={\"train\": IidPartitioner(num_partitions=num_partitions)}\n",
        "    )\n",
        "\n",
        "    # Define transforms\n",
        "    pytorch_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "        return batch\n",
        "\n",
        "    # Load and partition the dataset\n",
        "    partition = fds.load_partition(partition_id)\n",
        "    partition_train_test = partition.train_test_split(test_size=0.2, seed=42)\n",
        "    partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    trainloader = DataLoader(partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True)\n",
        "    valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Load the test set split (not partitioned)\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    return trainloader, valloader, testloader\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IegZUniri1tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram of the dataset\n"
      ],
      "metadata": {
        "id": "AosnHQ_ojGd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Download dataset\n",
        "mnist = load_dataset(\"ylecun/mnist\")\n",
        "\n",
        "# construct histogram\n",
        "all_labels = mnist[\"train\"][\"label\"]\n",
        "all_label_counts = Counter(all_labels)\n",
        "\n",
        "# visualise histogram\n",
        "bar = plt.bar(all_label_counts.keys(), all_label_counts.values())\n",
        "_ = plt.bar_label(bar)\n",
        "\n",
        "# plot formatting\n",
        "_ = plt.xticks([label for label in all_label_counts.keys()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "X44-OYzFi__q",
        "outputId": "49db639d-6997-47e5-f58c-86918a31974a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "BrJWWa_JjUTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zo5PCprRixcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net(num_classes=10)\n",
        "num_parameters = sum(value.numel() for value in model.state_dict().values())\n",
        "print(f\"{num_parameters = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBSI1-6bka1b",
        "outputId": "373f9873-4aa7-4e58-a449-331c6d25603d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_parameters = 44426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train test Func\n"
      ],
      "metadata": {
        "id": "bWjz0Nerendb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, optimizer, epochs):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    net.train()\n",
        "    for batch in trainloader:\n",
        "        images, labels = batch[\"image\"], batch[\"label\"]\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(net(images), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"image\"], batch[\"label\"]\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "acU_vF0fkmrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# centralised"
      ],
      "metadata": {
        "id": "957pzoxDewHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_centralised(\n",
        "    trainloader,\n",
        "    testloader,\n",
        "    epochs: int,\n",
        "    lr: float,\n",
        "    momentum: float = 0.9\n",
        "):\n",
        "\n",
        "    # instantiate the model\n",
        "    model = Net(num_classes=10)\n",
        "\n",
        "    # define optimiser with hyperparameters supplied\n",
        "    optim = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    # train for the specified number of epochs\n",
        "    for e in range(epochs):\n",
        "        print(f\"Training epoch {e} ...\")\n",
        "        train(model, trainloader, optim, epochs)\n",
        "\n",
        "    # training is completed, then evaluate model on the test set\n",
        "    loss, accuracy = test(model, testloader)\n",
        "    print(f\"{loss = }\")\n",
        "    print(f\"{accuracy = }\")"
      ],
      "metadata": {
        "id": "DI1gU4AzcnVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct dataloaders\n",
        "trainloader, _, testloader = load_datasets(partition_id=0, num_partitions=1)\n",
        "\n",
        "# Run the centralised training\n",
        "run_centralised(trainloader, testloader, epochs=5, lr=0.01)"
      ],
      "metadata": {
        "id": "FHUITDUzpy8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc82d3d-f7bb-41f9-a3ba-cd37ad2470b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 0 ...\n",
            "Training epoch 1 ...\n",
            "Training epoch 2 ...\n",
            "Training epoch 3 ...\n",
            "Training epoch 4 ...\n",
            "loss = 12.655296282486233\n",
            "accuracy = 0.9873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clients partitions\n"
      ],
      "metadata": {
        "id": "o-k8ZdyrxH7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import IidPartitioner\n",
        "\n",
        "NUM_PARTITIONS = 100\n",
        "\n",
        "partitioner = IidPartitioner(num_partitions=NUM_PARTITIONS)\n",
        "\n",
        "fds = FederatedDataset(dataset=\"ylecun/mnist\", partitioners={\"train\": partitioner})"
      ],
      "metadata": {
        "id": "zL6Qb_LXxLd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## homogenus distribution"
      ],
      "metadata": {
        "id": "-xTUj8cKxV60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "\n",
        "partition_0 = fds.load_partition(0)\n",
        "\n",
        "fig, ax, df = plot_label_distributions(\n",
        "    partitioner,\n",
        "    label_name=\"label\",\n",
        "    plot_type=\"bar\",\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        "    legend=True,\n",
        "    verbose_labels=True,\n",
        "    max_num_partitions=30,  # Note we are only showing the first 30 so the plot remains readable\n",
        "    title=\"Per Partition Labels Distribution\",\n",
        ")"
      ],
      "metadata": {
        "id": "tnHa0UJBxU1U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flwr client\n"
      ],
      "metadata": {
        "id": "3UzEPJxtfMJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set-get params\n"
      ],
      "metadata": {
        "id": "2cKphyyRfX73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Two auxhiliary functions to set and extract parameters of a model\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    # now replace the parameters\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    \"\"\"Extract model parameters as a list of NumPy arrays.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]"
      ],
      "metadata": {
        "id": "n8TluyQffXa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import torch\n",
        "from flwr.common import NDArrays, Scalar\n",
        "from flwr.client import NumPyClient\n",
        "\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id, trainloader, valloader, model):\n",
        "        super().__init__()\n",
        "        self.partition_id = partition_id\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.model = model\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "      #  Return the current local model parameters\n",
        "        print(f\"[Client {self.partition_id}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Receive parameters sent by the server into client's local model\n",
        "        print(f\"[Client {self.partition_id}] fit, config: {config}\")\n",
        "        set_params(self.model, parameters)\n",
        "\n",
        "        # # Define the optimizer\n",
        "        # optim = torch.optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "        # local training\n",
        "        train(self.model, self.trainloader, optim, epochs=1)\n",
        "        # return the model parameters to the server as well as extra info\n",
        "        return get_params(self.model), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        print(f\"[Client {self.partition_id}] evaluate, config: {config}\")\n",
        "        set_params(self.model, parameters)\n",
        "        # do local evaluation\n",
        "        loss, accuracy = test(self.model, self.valloader)\n",
        "        # send statistics back to the server\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}\n",
        "\n",
        "    def fit_config(server_round: int):\n",
        "        \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "        Perform two rounds of training with one local epoch, increase to two local\n",
        "        epochs afterwards.\n",
        "        \"\"\"\n",
        "        config = {\n",
        "            \"server_round\": server_round,  # The current round of federated learning\n",
        "            \"local_epochs\": 1 if server_round < 2 else 2,\n",
        "        }\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "7H-9V-mGyQPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## client func"
      ],
      "metadata": {
        "id": "pRjlq9UpaniV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr.common import Context\n",
        "from flwr.client import ClientApp\n",
        "\n",
        "\n",
        "def client_fn(context: Context) -> Client:\n",
        "    \"\"\"Returns a FlowerClient containing its data partition.\"\"\"\n",
        "    # Load model\n",
        "    model = Net(num_classes=10).to(DEVICE)\n",
        "\n",
        "    partition_id = int(context.node_config[\"partition-id\"])\n",
        "\n",
        "    ###################################################################################\n",
        "    # the client loads a full data partition\n",
        "    partition = fds.load_partition(partition_id, \"train\")\n",
        "    # partition into train/validation\n",
        "    partition_train_val = partition.train_test_split(test_size=0.1, seed=42)\n",
        "    # PARTITION DATA  each client gets a different trainloader/valloader to each client\n",
        "    trainloader, testloader = get_mnist_dataloaders(partition_train_val, batch_size=32)\n",
        "    ######################################################################################\n",
        "\n",
        "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
        "    return FlowerClient(partition_id, model, trainloader, testloader).to_client()\n"
      ],
      "metadata": {
        "id": "w48j76pjy9cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(context: Context) -> Client:\n",
        "\n",
        "    model = Net(num_classes=10).to(DEVICE)\n",
        "\n",
        "    # assigns the partition_id, num_partitions to each client\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "\n",
        "    #  pre-splited\n",
        "    trainloader, valloader, _ = load_datasets(partition_id, num_partitions)\n",
        "\n",
        "    return FlowerClient(partition_id, net, trainloader, valloader).to_client()"
      ],
      "metadata": {
        "id": "S56SlHeHcfny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concstruct the ClientApp\n",
        "client_app = ClientApp(client_fn=client_fn)"
      ],
      "metadata": {
        "id": "mbTu0HXLuX8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregation func\n"
      ],
      "metadata": {
        "id": "ROlMcjFCJ0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from flwr.common import Metrics\n",
        "\n",
        "\n",
        "# Define metric aggregation function\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "TOObI2DmJzIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strategies\n",
        "\n"
      ],
      "metadata": {
        "id": "9fjnJiGIyQgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy_1 = FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=10,  # Wait until all 10 clients are available\n",
        "    # initial_parameters, # initialised global model\n",
        ")"
      ],
      "metadata": {
        "id": "Io_f5Cs4wXqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy_2 = FedAvgCustom(\n",
        "        file_name=\"results_fedavgcustom\",\n",
        "        num_rounds=num_rounds,\n",
        "        fraction_fit=0.1,  # 10% clients sampled each round to do fit()\n",
        "        fraction_evaluate=0.25,  # 25% clients sample each round to do evaluate()\n",
        "        # min_fit_clients=10,\n",
        "        # min_evaluate_clients=5,\n",
        "        # min_available_clients=10, # Wait until all 10 clients are available\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # weighted average\n",
        "\n",
        "        initial_parameters=global_model_init,  # initialised global model\n",
        "\n",
        "        evaluate_fn=get_evaluate_fn(testloader),  # gloabl evaluation (here we can pass the same testset as used in centralised)\n",
        "    )"
      ],
      "metadata": {
        "id": "OqiONM_9w5oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strategy_3 = FedAdagrad(\n",
        "        fraction_fit=0.3,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "    )"
      ],
      "metadata": {
        "id": "EwczSjcy4F92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fed Avg Custom"
      ],
      "metadata": {
        "id": "B31ZLfjv13o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.common import Parameters\n",
        "import json\n",
        "\n",
        "\n",
        "class FedAvgCustom(FedAvg):\n",
        "    def __init__(self, file_name: str, num_rounds: int, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.file_name = file_name\n",
        "        self.num_rounds = num_rounds\n",
        "        self.loss_list = []\n",
        "        self.metrics_list = []\n",
        "\n",
        "    def _make_plot(self):\n",
        "        \"\"\"Makes a plot with the results recorded\"\"\"\n",
        "        round = list(range(1, len(self.loss_list) + 1))\n",
        "        acc = [100.0 * metrics[\"accuracy\"] for metrics in self.metrics_list]\n",
        "        plt.plot(round, acc)\n",
        "        plt.grid()\n",
        "        plt.ylabel(\"Accuracy (%)\")\n",
        "        plt.xlabel(\"Round\")\n",
        "\n",
        "    def evaluate(self, server_round: int, parameters: Parameters):\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        loss, metrics = super().evaluate(server_round, parameters)\n",
        "        # Record results\n",
        "        self.loss_list.append(loss)\n",
        "        self.metrics_list.append(metrics)\n",
        "        # If last round, save results and make a plot\n",
        "        if server_round == self.num_rounds:\n",
        "            # Save to CSV\n",
        "            with open(f\"{self.file_name}.json\", \"w\") as f:\n",
        "                json.dump({\"loss\": self.loss_list, \"metrics\": self.metrics_list}, f)\n",
        "            # Generate plot\n",
        "            self._make_plot()\n",
        "\n",
        "\n",
        "def get_evaluate_fn(testloader):\n",
        "    \"\"\"Return a function that can be called to do global evaluation.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"Evaluate global model on the whole test set.\"\"\"\n",
        "\n",
        "        model = Net(num_classes=10)\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        # call test (evaluate model as in centralised setting)\n",
        "        loss, accuracy = test(model, testloader)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ],
      "metadata": {
        "id": "pRitLk_mZHAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Server side\n"
      ],
      "metadata": {
        "id": "veLCHQizKOwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr.common import ndarrays_to_parameters\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server import ServerApp, ServerConfig\n",
        "\n",
        "\n",
        "def server_fn(context: Context):\n",
        "\n",
        "    # instantiate the model\n",
        "    model = Net(num_classes=10)\n",
        "    ndarrays = get_params(model)\n",
        "    # Convert model parameters to flwr.common.Parameters\n",
        "    global_model_init = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "    # Define the strategy\n",
        "\n",
        "    # Construct ServerConfig\n",
        "    config = ServerConfig()\n",
        "\n",
        "    # Wrap everything into a `ServerAppComponents` object\n",
        "    return ServerAppComponents(strategy=strategy_1, config=config)\n",
        "\n",
        "\n",
        "# Create your ServerApp\n",
        "server_app = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "YCvZvtflKJz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run\n"
      ],
      "metadata": {
        "id": "wu6GSVlkKXdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# each client will be allocated 2x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": None}\n",
        "\n",
        "# each client will be allocated 1x CPU and 0x GPUs\n",
        "# backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n"
      ],
      "metadata": {
        "id": "ovtCtM2Oxa0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr.simulation import run_simulation\n",
        "\n",
        "num_rounds = 5\n",
        "\n",
        "run_simulation(\n",
        "    server_app=server_app,\n",
        "    num_rounds=num_rounds,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=NUM_CLIENTS,# each group train locally and send their updates to the supernode for aggregation\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "VVoWwSDzKWmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Server-side parameter evaluation"
      ],
      "metadata": {
        "id": "xjdz_DSXXr_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate func on server"
      ],
      "metadata": {
        "id": "HZgTEJLVYhSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The `evaluate` function will be called by Flower after every round\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: NDArrays,\n",
        "    config: Dict[str, Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "    net = Net().to(DEVICE)\n",
        "    _, _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "iu0f1jiSXd5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strat"
      ],
      "metadata": {
        "id": "t-u3lNbWYrtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = FedAvg(\n",
        "        fraction_fit=0.3,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "        evaluate_fn=evaluate,  # Pass the evaluation function\n",
        "    )"
      ],
      "metadata": {
        "id": "p_GXOMTbYfse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Server func"
      ],
      "metadata": {
        "id": "sRJD9BQiYuzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def server_fn(context: Context):\n",
        "    # Define the strategy\n",
        "\n",
        "    # Construct ServerConfig (num_rounds defined in the run funcion)\n",
        "    config = ServerConfig()\n",
        "\n",
        "    # Wrap everything into a `ServerAppComponents` object\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create your ServerApp\n",
        "server_app = ServerApp(server_fn=server_fn)"
      ],
      "metadata": {
        "id": "FlgSDenaX607"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "ilWcdqNCYxWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flwr.simulation import run_simulation\n",
        "\n",
        "num_rounds = 5\n",
        "\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    num_rounds=num_rounds,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_PARTITIONS,# each group train locally and send their updates to the supernode for aggregation\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "id": "iOXOevZNYZTm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}